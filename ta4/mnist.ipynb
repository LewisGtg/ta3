{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "400d8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467a9e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando o dataset MNIST...\n",
      "Shape dos dados: (70000, 784), Labels: (70000,)\n",
      "Shape dos dados: (70000, 784), Labels: (70000,)\n"
     ]
    }
   ],
   "source": [
    "# 1. Carregar o dataset MNIST\n",
    "print(\"Carregando o dataset MNIST...\")\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y = mnist.data, mnist.target.astype(int)\n",
    "print(f\"Shape dos dados: {X.shape}, Labels: {y.shape}\")\n",
    "\n",
    "# Inicializar dicionário para salvar resultados\n",
    "results = {\n",
    "    'timestamp': datetime.datetime.now().isoformat(),\n",
    "    'dataset_info': {\n",
    "        'shape': X.shape,\n",
    "        'num_classes': len(np.unique(y)),\n",
    "        'classes': np.unique(y).tolist()\n",
    "    },\n",
    "    'experiments': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8741368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Funções auxiliares\n",
    "def split_data(X, y, train_size, val_size, test_size, random_state=42):\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, train_size=train_size, random_state=random_state, stratify=y)\n",
    "    val_relative_size = val_size / (val_size + test_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, train_size=val_relative_size, random_state=random_state, stratify=y_temp)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def apply_pca(X_train, X_val, X_test, n_components=0.95):\n",
    "    pca = PCA(n_components=n_components, whiten=True, random_state=42)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    print(f\"PCA: de {X_train.shape[1]} para {X_train_pca.shape[1]} dimensões.\")\n",
    "    return X_train_pca, X_val_pca, X_test_pca, pca\n",
    "\n",
    "def train_knn(X_train, y_train, X_val, y_val, k, metric='euclidean'):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric=metric, n_jobs=-1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_val_pred = knn.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"k-NN (k={k}, metric={metric}): Validação: {acc:.4f}\")\n",
    "    return knn, acc\n",
    "\n",
    "def train_logistic(X_train, y_train, X_val, y_val):\n",
    "    clf = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial', n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Logistic Regression: Validação: {acc:.4f}\")\n",
    "    return clf, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca835e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dividindo os dados...\n",
      "Aplicando PCA...\n",
      "Aplicando PCA...\n",
      "PCA: de 784 para 154 dimensões.\n",
      "PCA: de 784 para 154 dimensões.\n"
     ]
    }
   ],
   "source": [
    "# 3. Divisão dos dados e PCA\n",
    "print(\"\\nDividindo os dados...\")\n",
    "# Exemplo: 60% treino, 20% validação, 20% teste\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y, 0.6, 0.2, 0.2)\n",
    "\n",
    "print(\"Aplicando PCA...\")\n",
    "X_train_pca, X_val_pca, X_test_pca, pca = apply_pca(X_train, X_val, X_test, n_components=0.95)\n",
    "\n",
    "# Adicionar informações do PCA aos resultados\n",
    "results['pca_info'] = {\n",
    "    'original_dimensions': X_train.shape[1],\n",
    "    'reduced_dimensions': X_train_pca.shape[1],\n",
    "    'variance_explained': float(pca.explained_variance_ratio_.sum())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e400443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experimentos com k-NN ===\n",
      "k-NN (k=3, metric=euclidean): Validação: 0.9006\n",
      "k-NN (k=3, metric=euclidean): Validação: 0.9006\n",
      "Teste k-NN (k=3, metric=euclidean): 0.8997\n",
      "\n",
      "Teste k-NN (k=3, metric=euclidean): 0.8997\n",
      "\n",
      "k-NN (k=5, metric=euclidean): Validação: 0.8965\n",
      "k-NN (k=5, metric=euclidean): Validação: 0.8965\n",
      "Teste k-NN (k=5, metric=euclidean): 0.8934\n",
      "\n",
      "Teste k-NN (k=5, metric=euclidean): 0.8934\n",
      "\n",
      "k-NN (k=7, metric=euclidean): Validação: 0.8890\n",
      "k-NN (k=7, metric=euclidean): Validação: 0.8890\n",
      "Teste k-NN (k=7, metric=euclidean): 0.8839\n",
      "\n",
      "Teste k-NN (k=7, metric=euclidean): 0.8839\n",
      "\n",
      "k-NN (k=3, metric=manhattan): Validação: 0.9049\n",
      "k-NN (k=3, metric=manhattan): Validação: 0.9049\n",
      "Teste k-NN (k=3, metric=manhattan): 0.9032\n",
      "\n",
      "Teste k-NN (k=3, metric=manhattan): 0.9032\n",
      "\n",
      "k-NN (k=5, metric=manhattan): Validação: 0.8983\n",
      "k-NN (k=5, metric=manhattan): Validação: 0.8983\n",
      "Teste k-NN (k=5, metric=manhattan): 0.8955\n",
      "\n",
      "Teste k-NN (k=5, metric=manhattan): 0.8955\n",
      "\n",
      "k-NN (k=7, metric=manhattan): Validação: 0.8906\n",
      "k-NN (k=7, metric=manhattan): Validação: 0.8906\n",
      "Teste k-NN (k=7, metric=manhattan): 0.8865\n",
      "\n",
      "Teste k-NN (k=7, metric=manhattan): 0.8865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Experimentos com k-NN\n",
    "print(\"\\n=== Experimentos com k-NN ===\")\n",
    "for metric in ['euclidean', 'manhattan']:\n",
    "    for k in [3, 5, 7]:\n",
    "        knn, val_acc = train_knn(X_train_pca, y_train, X_val_pca, y_val, k, metric)\n",
    "        y_test_pred = knn.predict(X_test_pca)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        print(f\"Teste k-NN (k={k}, metric={metric}): {test_acc:.4f}\\n\")\n",
    "        \n",
    "        # Salvar resultados\n",
    "        experiment_result = {\n",
    "            'algorithm': 'k-NN',\n",
    "            'parameters': {'k': k, 'metric': metric},\n",
    "            'validation_accuracy': float(val_acc),\n",
    "            'test_accuracy': float(test_acc)\n",
    "        }\n",
    "        results['experiments'].append(experiment_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e929c19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experimentos com Logistic Regression ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lewis/ufpr/ta3/ta4/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Validação: 0.9195\n",
      "Teste Logistic Regression: 0.9199\n"
     ]
    }
   ],
   "source": [
    "# 5. Experimentos com Classificador Linear\n",
    "print(\"\\n=== Experimentos com Logistic Regression ===\")\n",
    "logistic, val_acc = train_logistic(X_train_pca, y_train, X_val_pca, y_val)\n",
    "y_test_pred = logistic.predict(X_test_pca)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Teste Logistic Regression: {test_acc:.4f}\")\n",
    "\n",
    "# Salvar resultados da Regressão Logística\n",
    "experiment_result = {\n",
    "    'algorithm': 'Logistic Regression',\n",
    "    'parameters': {'max_iter': 1000, 'solver': 'lbfgs', 'multi_class': 'multinomial'},\n",
    "    'validation_accuracy': float(val_acc),\n",
    "    'test_accuracy': float(test_acc)\n",
    "}\n",
    "results['experiments'].append(experiment_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "960702b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Avaliação Final ===\n",
      "Matriz de Confusão:\n",
      "[[1339    0    4    2    2   12    6    3    7    5]\n",
      " [   1 1535    6    6    1    5    0    4   14    3]\n",
      " [  11   13 1253   26   15    6   23   20   23    8]\n",
      " [   8   11   29 1267    1   50    7   19   27   10]\n",
      " [   3    8    8    7 1264    0   12    5   10   48]\n",
      " [  14    7   20   34   10 1098   24    2   41   13]\n",
      " [  10    5   17    1    9   13 1314    2    4    0]\n",
      " [   3    6   18    8   11    2    0 1362    5   44]\n",
      " [  15   27   17   33   11   39   14    6 1191   12]\n",
      " [  12    5    6   17   42   10    1   33    9 1256]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1380\n",
      "           1       0.95      0.97      0.96      1575\n",
      "           2       0.91      0.90      0.90      1398\n",
      "           3       0.90      0.89      0.90      1429\n",
      "           4       0.93      0.93      0.93      1365\n",
      "           5       0.89      0.87      0.88      1263\n",
      "           6       0.94      0.96      0.95      1375\n",
      "           7       0.94      0.93      0.93      1459\n",
      "           8       0.89      0.87      0.88      1365\n",
      "           9       0.90      0.90      0.90      1391\n",
      "\n",
      "    accuracy                           0.92     14000\n",
      "   macro avg       0.92      0.92      0.92     14000\n",
      "weighted avg       0.92      0.92      0.92     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Avaliação final\n",
    "print(\"\\n=== Avaliação Final ===\")\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "class_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Adicionar avaliação final aos resultados\n",
    "results['final_evaluation'] = {\n",
    "    'confusion_matrix': conf_matrix.tolist(),\n",
    "    'classification_report': class_report,\n",
    "    'best_algorithm': max(results['experiments'], key=lambda x: x['test_accuracy'])['algorithm'],\n",
    "    'best_test_accuracy': max(results['experiments'], key=lambda x: x['test_accuracy'])['test_accuracy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cb3b0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resultados salvos em mnist_experiments_20250608_172159.json ===\n",
      "Melhor algoritmo: Logistic Regression\n",
      "Melhor acurácia de teste: 0.9199\n",
      "Resumo salvo em mnist_summary_20250608_172159.txt\n"
     ]
    }
   ],
   "source": [
    "# 7. Salvar resultados em arquivo\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_filename = f\"mnist_experiments_{timestamp}.json\"\n",
    "\n",
    "with open(results_filename, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\n=== Resultados salvos em {results_filename} ===\")\n",
    "print(f\"Melhor algoritmo: {results['final_evaluation']['best_algorithm']}\")\n",
    "print(f\"Melhor acurácia de teste: {results['final_evaluation']['best_test_accuracy']:.4f}\")\n",
    "\n",
    "# Salvar também um resumo em texto\n",
    "summary_filename = f\"mnist_summary_{timestamp}.txt\"\n",
    "with open(summary_filename, 'w') as f:\n",
    "    f.write(f\"MNIST Classification Experiments - {results['timestamp']}\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    f.write(f\"Dataset Info:\\n\")\n",
    "    f.write(f\"  Shape: {results['dataset_info']['shape']}\\n\")\n",
    "    f.write(f\"  Number of classes: {results['dataset_info']['num_classes']}\\n\\n\")\n",
    "    f.write(f\"PCA Info:\\n\")\n",
    "    f.write(f\"  Original dimensions: {results['pca_info']['original_dimensions']}\\n\")\n",
    "    f.write(f\"  Reduced dimensions: {results['pca_info']['reduced_dimensions']}\\n\")\n",
    "    f.write(f\"  Variance explained: {results['pca_info']['variance_explained']:.4f}\\n\\n\")\n",
    "    f.write(\"Experiment Results:\\n\")\n",
    "    for exp in results['experiments']:\n",
    "        f.write(f\"  {exp['algorithm']}: Val={exp['validation_accuracy']:.4f}, Test={exp['test_accuracy']:.4f}\\n\")\n",
    "    f.write(f\"\\nBest Algorithm: {results['final_evaluation']['best_algorithm']}\\n\")\n",
    "    f.write(f\"Best Test Accuracy: {results['final_evaluation']['best_test_accuracy']:.4f}\\n\")\n",
    "\n",
    "print(f\"Resumo salvo em {summary_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fcbba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Criar arquivo CSV com os resultados\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Preparar dados para CSV\n",
    "csv_data = []\n",
    "for exp in results['experiments']:\n",
    "    row = {\n",
    "        'Algorithm': exp['algorithm'],\n",
    "        'Validation_Accuracy': exp['validation_accuracy'],\n",
    "        'Test_Accuracy': exp['test_accuracy']\n",
    "    }\n",
    "    \n",
    "    # Adicionar parâmetros específicos\n",
    "    for param, value in exp['parameters'].items():\n",
    "        row[param] = value\n",
    "    \n",
    "    csv_data.append(row)\n",
    "\n",
    "# Criar DataFrame e salvar CSV\n",
    "df = pd.DataFrame(csv_data)\n",
    "csv_filename = f\"mnist_results_{timestamp}.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"\\n=== Resultados CSV salvos em {csv_filename} ===\")\n",
    "print(\"\\nTabela de Resultados:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Criar também um CSV mais detalhado com métricas por classe\n",
    "detailed_csv_data = []\n",
    "for class_num in range(10):\n",
    "    class_str = str(class_num)\n",
    "    if class_str in class_report:\n",
    "        detailed_csv_data.append({\n",
    "            'Class': class_num,\n",
    "            'Precision': class_report[class_str]['precision'],\n",
    "            'Recall': class_report[class_str]['recall'],\n",
    "            'F1_Score': class_report[class_str]['f1-score'],\n",
    "            'Support': int(class_report[class_str]['support'])\n",
    "        })\n",
    "\n",
    "# Adicionar métricas gerais\n",
    "detailed_csv_data.append({\n",
    "    'Class': 'Overall',\n",
    "    'Precision': class_report['weighted avg']['precision'],\n",
    "    'Recall': class_report['weighted avg']['recall'],\n",
    "    'F1_Score': class_report['weighted avg']['f1-score'],\n",
    "    'Support': int(class_report['weighted avg']['support'])\n",
    "})\n",
    "\n",
    "df_detailed = pd.DataFrame(detailed_csv_data)\n",
    "detailed_csv_filename = f\"mnist_detailed_metrics_{timestamp}.csv\"\n",
    "df_detailed.to_csv(detailed_csv_filename, index=False)\n",
    "\n",
    "print(f\"\\nMétricas detalhadas salvas em {detailed_csv_filename}\")\n",
    "print(\"\\nMétricas por Classe:\")\n",
    "print(df_detailed.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
